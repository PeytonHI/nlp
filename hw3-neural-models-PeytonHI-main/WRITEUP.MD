[Engagingness] How much did you enjoy talking to this user?
Somewhat. I enjoy the fact that it's actually outputting something based on the documents I fed the model and showing me which documents are being used.
[Interestingness] How interesting or boring did you find this conversation?
A little boring. It seems to hallucinate due to a lack of relevant data. I think having it output a percentage of correctness isn't helping.
[Inquisitiveness] How much did the user try to get to know you?
N/A
[Listening] How much did the user seem to pay attention to what you said?
N/A
[Avoiding Repetition] How repetitive was this user?
Very. Often claimed it didn't have enough supporting evidence to make a verdict. 
[Fluency] How naturally did this user speak English?
• Very unnatural • Mostly unnatural • Mostly natural • Very natural
Mostly Natural
[Making sense] How often did this user say something which did NOT make sense?
• Never made any sense • Most responses didn’t make sense
• Some responses didn’t make sense • Everything made perfect sense
Some responses didn't make sense. 
[Humanness] Do you think this user is a bot or a human?
• Definitely a bot • Probably a bot • Probably a human • Definitely a human
Definitely a bot
[Persona retrieval] Which prompt (character) do you think the other user was given
for this conversation?
Respondent chooses one of two provided personas

Definitely assistant for the fact checking task.